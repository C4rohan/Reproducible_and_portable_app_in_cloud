## Reproduce: reproduce existing execution with RPAC

The [reproduce](../reproduce) folder includes the pipeline file that generated by RPAC. RPAC toolkit will execute big data analytics in cloud based on all files in this folder.

We use CloudRetrievalViaDask application in AWS Cloud as the tutorial example.

After an application has been executed, clients can reproduce it with its execution history. Our RPAC toolkit helps the client generate a pipeline file based on their preferences. 

> For example, in execution history as the figure shown, users enable to retrieval the source dataset, command line, pipeline file and execution events from recorded storage addresses.
<p align="center"><img src="./figures/db_item.png"/></p>
<p align="center"><img src="./figures/s3_logs.png"/></p>

1. Download execution history files from storage, replace tamplate files in `./AwsServerlessTemplate/CloudRetrievalViaDask` folder with the downloaded files.

   - The lambda zip file (like "820b160bfc1a7c544ac3a14c188c8203") -> ./AwsServerlessTemplate/CloudRetrievalViaDask/lambda
   - The pipline file (like "613b72df0491f49de3f851cfcc1ade77.template") -> ./AwsServerlessTemplate/CloudRetrievalViaDask/deploy_config.json
   - The execution event file (like "event.json") -> ./AwsServerlessTemplate/CloudRetrievalViaDask/SampleEvent.json

2. Also provide user personal information in `./ConfigTemplate/personal.ini`. If user want to reproduce execution with different application or resource configurations, please also edit `./ConfigTemplate/application.ini` and `./ConfigTemplate/resource.ini`.

3. Run `python3 main.py` to start RPAC for reproduction. With user-provided personal information and historical execution, a new pipeline will be generated in `./reproduce` folder.
